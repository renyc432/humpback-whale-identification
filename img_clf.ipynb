{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB0, VGG19\n",
    "from tensorflow.keras.applications.efficientnet import decode_predictions\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Softmax, BatchNormalization, Input\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, LambdaCallback\n",
    "from keras.layers.experimental import preprocessing\n",
    "\n",
    "from keras.optimizers import schedules\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir='../../data/train'\n",
    "test_img_dir='../../data/test'\n",
    "train_csv_path = '../../data/train.csv'\n",
    "test_csv_path = '../../data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_csv_path)\n",
    "test = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config settings\n",
    "class CONFIG:\n",
    "    # image loading\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    # nn training\n",
    "    epochs = 100\n",
    "    batch_size = 128\n",
    "    lr = 1e-5\n",
    "    \n",
    "    # callbacks\n",
    "    checkpoint_filepath = './temp/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG only: sample subset of the data\n",
    "train_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = util.load_img_RGB(train_img_dir,train.Image[:train_size], CONFIG.img_width, CONFIG.img_height)\n",
    "X_train /= 255\n",
    "y_train = np.array(train.Id[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode y\n",
    "y_train_encoded, label_encoder = util.prepare_labels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try stratified split, if doesn't work, use train_test_split\n",
    "try:\n",
    "    X_train, y_train, X_val, y_val = util.split(X_train,y_train_encoded,0.2)\n",
    "except:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,y_train_encoded,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_num_nodes = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained layers\n",
    "efn_pretrained = EfficientNetB0(weights='imagenet',\n",
    "                                include_top=False,\n",
    "                                input_shape=(CONFIG.img_width, CONFIG.img_height,3))\n",
    "for layer in efn_pretrained.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add top layers\n",
    "\n",
    "#new_layers = GlobalAveragePooling2D(name=\"avg_pool\")(efn_pretrained.output)\n",
    "new_layers = Flatten()(efn_pretrained.output)\n",
    "new_layers = Dense(1024, kernel_initializer=\"he_normal\", activation=\"relu\")(new_layers)\n",
    "new_layers = Dense(1024, kernel_initializer=\"he_normal\", activation=\"relu\")(new_layers)\n",
    "new_layers = BatchNormalization()(new_layers)\n",
    "new_layers = Dropout(0.5)(new_layers)\n",
    "new_layers = Dense(dense_num_nodes, kernel_initializer=\"he_normal\", activation=\"relu\")(new_layers)\n",
    "predictions = Softmax()(new_layers)\n",
    "efn_whale = Model(efn_pretrained.input, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler: a few options\n",
    "scheduler_exp = schedules.ExponentialDecay(0.0001, decay_steps=100000, decay_rate=1e-6)\n",
    "#scheduler_inverse = schedules.InverseTimeDecay()\n",
    "#scheduler_poly = schedules.PolynomialDecay()\n",
    "#scheduler_piecewise = schedules.PiecewiseConstantDecay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer: a few options\n",
    "#adam = optimizers.Adam(CONFIG.lr,clipnorm=0.1)\n",
    "adam = optimizers.Adam(scheduler_exp,clipnorm=0.1)\n",
    "#nadam = optimizers.Nadam(CONFIG.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: logs.get('weights') - dn work right now\n",
    "class WeightHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "       self.weights = [] \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "       self.weights.append(logs.get('weights'))\n",
    "#       self.weights.append(efn_shopee.layers[242].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_hist = WeightHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=20,restore_best_weights=True)\n",
    "    # ModelCheckpoint(filepath=CONFIG.checkpoint_filepath,save_best_only=True),\n",
    "    # print_weights = LambdaCallback(on_batch_begin=lambda batch, logs: print(efn_shopee.layers[242].get_weights()))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably should be 'categorical_crossentropy' because y is one hot encoded\n",
    "efn_whale.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                  optimizer = adam, \n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "history = efn_whale.fit(\n",
    "    X_train, y_train, \n",
    "    batch_size=CONFIG.batch_size, epochs=CONFIG.epochs, verbose=1,\n",
    "    shuffle=True, validation_data=(X_val,y_val),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
